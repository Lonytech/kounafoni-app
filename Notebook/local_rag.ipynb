{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "    - Ollama -> See : https://ollama.com/download\n",
    "  - For linux users :\n",
    "    \n",
    "    For this tutorial, run these instructions\n",
    "    - Install Ollama : `curl -fsSL https://ollama.com/install.sh | sh`\n",
    "    - Pull required models : \n",
    "        - `ollama pull mayflowergmbh/occiglot-7b-fr-en-instruct` #french llm model\n",
    "        - `ollama pull sammcj/sfr-embedding-mistral:Q4_K_M` # decent embedding for this use case\n",
    "    \n",
    "    -------------------------------------------------------------------------------\n",
    "  \n",
    "    Additional informations about Ollama\n",
    "    - To remove Ollama : https://github.com/ollama/ollama/blob/main/docs/linux.md\n",
    "    - To stop ollama server : `systemctl stop ollama`\n",
    "    - To restart server : `systemctl start ollama`\n",
    "    \n",
    "    -------------------------------------------------------------------------------\n",
    "    Due to issues from Ollama's latest versions in weights update, we might want to install older versions of Ollama.\n",
    "    To install **v.0.1.31** on Linux:\n",
    "      - `curl -fsSL https://ollama.com/install.sh | sed 's#https://ollama.com/download/ollama-linux-${ARCH}${VER_PARAM}#https://github.com/ollama/ollama/releases/download/v0.1.31/ollama-linux-amd64#' | sh`\n",
    "            \n",
    "- Next steps\n",
    "    - Add source for response provided by the chatbot (e.g., source: from 'Le Challenger' via 'Malijet'. To know more, here are some useful links: links...)\n",
    "    - Improve model response (accuracy and precision)\n"
   ],
   "id": "1b3ffc25e5487cf2"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T20:01:42.399018Z",
     "start_time": "2024-05-23T20:01:41.703558Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "# from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "# from langchain_openai.embeddings import OpenAIEmbeddings"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:01:43.091517Z",
     "start_time": "2024-05-23T20:01:43.086827Z"
    }
   },
   "cell_type": "code",
   "source": "%env OPENAI_API_KEY=sk-xxx",
   "id": "fa0970cb82d4cc0e",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:01:43.392525Z",
     "start_time": "2024-05-23T20:01:43.388428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ARTICLE_SOURCE_FILE_PATH = Path().resolve().parent /\"data\" / \"malijet\" / \"source.csv\"\n",
    "CHROMA_DB_PERSIST_PATH = Path().resolve().parent / \"data\" / \"chroma_db\"\n",
    "MODEL_NAME = \"mayflowergmbh/occiglot-7b-fr-en-instruct\""
   ],
   "id": "1e5d62f9058c6a59",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:01:43.982790Z",
     "start_time": "2024-05-23T20:01:43.975759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get nb cpu\n",
    "os.cpu_count()"
   ],
   "id": "5fc57ddc9742470d",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:01:54.990347Z",
     "start_time": "2024-05-23T20:01:54.980357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system_role = \"Tu es un expert sur les actualités du Mali et tu parles uniquement français (spécialisé en langue française).\"\n",
    "llm = Ollama(model=MODEL_NAME, system=system_role, num_thread=os.cpu_count()-6)\n",
    "llm"
   ],
   "id": "609b90e8d6c8fa64",
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Testing Simple LLM discussion",
   "id": "79883c6433748c08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:03:02.741923Z",
     "start_time": "2024-05-23T20:02:01.895525Z"
    }
   },
   "cell_type": "code",
   "source": "llm.invoke(\"Cite moi les noms des présidents du Mali.\")",
   "id": "3c93a18536ce0ae5",
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:21.743327Z",
     "start_time": "2024-05-23T20:03:02.767906Z"
    }
   },
   "cell_type": "code",
   "source": "llm.invoke(\"Quelle est la plus grande crise que la Mali a connue ?\")",
   "id": "7a2a5487f0d95608",
   "execution_count": 7,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:46.931884Z",
     "start_time": "2024-05-23T20:04:21.746175Z"
    }
   },
   "cell_type": "code",
   "source": "llm.invoke(\"Who is the most popular scientist in the world?\")",
   "id": "abbaf94d1945f818",
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Build RAG with CSV file",
   "id": "72e4efb57cc1c09b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:46.970570Z",
     "start_time": "2024-05-23T20:04:46.935533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loader = CSVLoader(\n",
    "    file_path=ARTICLE_SOURCE_FILE_PATH,\n",
    "    csv_args={\n",
    "        \"delimiter\": \"\\t\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# load documents\n",
    "data = loader.load()\n",
    "data[:3] # three first documents"
   ],
   "id": "e79a45440193a7cb",
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.116406Z",
     "start_time": "2024-05-23T20:04:46.972645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 53 articles extracted\n",
    "len(data), pd.read_csv(ARTICLE_SOURCE_FILE_PATH, sep=\"\\t\").shape[0]"
   ],
   "id": "873e297d2e8bea8e",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Let's see if the splitter is necessary",
   "id": "9c4aaff6953733cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Without splitter",
   "id": "f002488cec5b6f14"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.130299Z",
     "start_time": "2024-05-23T20:04:47.118159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_length_info(list_of_documents, splitters=None):\n",
    "    \n",
    "    if splitters is None:\n",
    "        splitters = [' ', '.']\n",
    "    \n",
    "    ## search the content length statistics (nb characters)\n",
    "    print('-'*10, \"For character length\", '-'*10)\n",
    "    display(pd.Series([len(document.page_content) for document in list_of_documents]).describe())\n",
    "    \n",
    "    ## search the words length statistics (nb words)\n",
    "    print('-'*10, \"Length of words (nb characters) in the corpus\", '-'*10)\n",
    "    _res = list()\n",
    "    for document in list_of_documents:\n",
    "        _res += pd.Series(document.page_content.split(splitters[0])).apply(len).tolist()\n",
    "    display(pd.Series(_res).describe())\n",
    "    \n",
    "    ## search the sentence length statistics (nb words)\n",
    "    print('-'*10, \"How many words in each doc\", '-'*10)\n",
    "    display(pd.Series([len(doc.page_content.split(splitters[0])) for doc in list_of_documents]).describe())\n",
    "    \n",
    "    ## search the sentence length statistics (nb words)\n",
    "    print('-'*10, \"For how many sentences in in each doc\", '-'*10)\n",
    "    display(pd.Series([len(doc.page_content.split(splitters[1])) for doc in list_of_documents]).describe())\n",
    "    \n",
    "    ## search the sentence length statistics (nb words)\n",
    "    print('-'*10, \"For sentences length in each doc\", '-'*10)\n",
    "    display(pd.Series([len(sentence) for document in list_of_documents for sentence in document.page_content.split('.')]).describe())\n",
    "    \n",
    "    return _res"
   ],
   "id": "d7ab01346dd7721b",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.258095Z",
     "start_time": "2024-05-23T20:04:47.132670Z"
    }
   },
   "cell_type": "code",
   "source": "res = get_length_info(data)",
   "id": "8f383d02d93be293",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## With splitter",
   "id": "a2da7035ac0fa051"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.284561Z",
     "start_time": "2024-05-23T20:04:47.259904Z"
    }
   },
   "cell_type": "code",
   "source": "pd.Series(res).max(), pd.Series(res).quantile(.99)",
   "id": "e894f4831744b1b6",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.292361Z",
     "start_time": "2024-05-23T20:04:47.285979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# quantile = int(pd.Series([len(sentence) for document in data for sentence in document.page_content.split('.')]).quantile(.95))\n",
    "quantile = 387 # first version\n",
    "maxi_character_per_chunk = pd.Series([len(sentence) for document in data for sentence in document.page_content.split('.')]).max().astype(int)\n",
    "maxi_character_per_words = 20 # over 16 to make sure to get all-content overlap\n",
    "quantile, maxi_character_per_chunk, maxi_character_per_words"
   ],
   "id": "cc766a25eedffec",
   "execution_count": 14,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "How do I determine how many characters form a meaningful chunk (i.e., understandable and self-sufficient information)?\n",
    "We will assume that each sentence could be a meaningful chunk. The idea is to have a count distribution of sentences length in our corpus to make a quick decision.\n",
    "- We might choose 400 (similar to the quantile q95) as chunk size to be more flexible. In this case, we stay with 387 as a chunk size\n",
    "- Also, in this case, we'll set 20 as the maximum length of character possible in a sentence"
   ],
   "id": "a7660197a0a2f201"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.324887Z",
     "start_time": "2024-05-23T20:04:47.295685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## test the document splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=quantile, # selected quantile\n",
    "    chunk_overlap=maxi_character_per_words,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"], # specify that sentence split (by dot) is more important than space & other\n",
    "    keep_separator=False # drop the separators from the document after split\n",
    ")\n",
    "documents = text_splitter.split_documents(documents=data)\n",
    "len(documents)"
   ],
   "id": "748bcce94fc43827",
   "execution_count": 15,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.330352Z",
     "start_time": "2024-05-23T20:04:47.326015Z"
    }
   },
   "cell_type": "code",
   "source": "documents[8:20]",
   "id": "a9f794b440aab2fd",
   "execution_count": 16,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.493593Z",
     "start_time": "2024-05-23T20:04:47.331920Z"
    }
   },
   "cell_type": "code",
   "source": "res = get_length_info(documents)",
   "id": "4cd8692686406b36",
   "execution_count": 17,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " We move from 4616 words maxi per doc to 79 words per doc. That might be relevant for the final framework of RAG.",
   "id": "811f82dc75521e64"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.498355Z",
     "start_time": "2024-05-23T20:04:47.494653Z"
    }
   },
   "cell_type": "code",
   "source": "[doc.page_content for doc in documents[:5]]",
   "id": "8c20dcaa549487bc",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.502213Z",
     "start_time": "2024-05-23T20:04:47.499424Z"
    }
   },
   "cell_type": "code",
   "source": "[doc.page_content for doc in documents[37:40]]",
   "id": "12684ae1fc5de49a",
   "execution_count": 19,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Embedding and Vector store",
   "id": "e6838d0a9aba8eff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.511475Z",
     "start_time": "2024-05-23T20:04:47.503556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# embeddings_llm = OllamaEmbeddings(model=MODEL_NAME) #mistral or Occiglot\n",
    "# embeddings_llm = OllamaEmbeddings(model=\"mayflowergmbh/occiglot-7b-fr-en-instruct\")\n",
    "# embeddings_llm = OllamaEmbeddings(model=\"snowflake-arctic-embed\")\n",
    "# embeddings_llm = OpenAIEmbeddings()\n",
    "\n",
    "embeddings_llm = OllamaEmbeddings(model=\"sammcj/sfr-embedding-mistral:Q4_K_M\")\n",
    "\n",
    "# Set few params if needed\n",
    "embeddings_llm.show_progress = True\n",
    "embeddings_llm.num_thread = os.cpu_count() - 8 # 8 in my case\n",
    "# embeddings_llm.top_k = 10\n",
    "# embeddings_llm.top_p = .5\n",
    "\n",
    "embeddings_llm"
   ],
   "id": "4cef3c3a490fec01",
   "execution_count": 20,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:04:47.517602Z",
     "start_time": "2024-05-23T20:04:47.512894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Exemple\n",
    "documents[3], len(documents[3].page_content)"
   ],
   "id": "70f7aa1256ac622f",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:41.864104Z",
     "start_time": "2024-05-23T20:04:47.518778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test to embed a query\n",
    "embeddings_llm.embed_query(documents[3].page_content)[:7], len(embeddings_llm.embed_query(documents[3].page_content))"
   ],
   "id": "bb2949b778aa79cf",
   "execution_count": 22,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Selection of Vector Store",
   "id": "31641f755d1e6b3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Thanks to this brand-new article from Google, we can safely choose any open source Vector Store, make it available to Google NFS Filestore and access it easily through mounting filestore in Cloud Run (see section 3): https://cloud.google.com/blog/products/serverless/introducing-cloud-run-volume-mounts?hl=en",
   "id": "d06c33240e392a47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:41.875441Z",
     "start_time": "2024-05-23T20:05:41.869634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# The embedding is a very large dimension of 4096, so this will take a real long time\n",
    "# Database creation\n",
    "# db = Chroma.from_documents(\n",
    "#     documents=documents[:2],\n",
    "#     embedding=embeddings_llm,\n",
    "#     persist_directory=CHROMA_DB_PERSIST_PATH.as_posix(),\n",
    "# )\n",
    "# db"
   ],
   "id": "2af8b4236d4b4c30",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:43.543973Z",
     "start_time": "2024-05-23T20:05:41.876986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db = Chroma(\n",
    "    persist_directory=CHROMA_DB_PERSIST_PATH.as_posix(),\n",
    "    embedding_function=embeddings_llm,\n",
    ")\n",
    "\n",
    "persisted_ids = db.get()[\"ids\"]\n",
    "\n",
    "new_documents_to_embed_df = pd.DataFrame({\n",
    "    \"single_id\": [str(uuid.uuid5(uuid.NAMESPACE_DNS, doc.page_content)) for doc in documents],\n",
    "    \"document\": documents\n",
    "})\n",
    "\n",
    "# to keep only different documents (i.e. chunks)\n",
    "new_documents_to_embed_df.drop_duplicates(subset=\"single_id\", inplace=True)\n",
    "\n",
    "# Keep only documents not already embedded\n",
    "new_documents_to_embed_df = new_documents_to_embed_df.query(f\"single_id not in {persisted_ids}\")\n",
    "\n",
    "if new_documents_to_embed_df.empty:\n",
    "    print(\"No documents to embed\")\n",
    "else:\n",
    "    print(\"Embedding documents...\")\n",
    "    display(new_documents_to_embed_df.head())\n",
    "    db.add_documents(\n",
    "        documents=new_documents_to_embed_df.document.tolist(), \n",
    "        embedding=embeddings_llm, \n",
    "        ids=new_documents_to_embed_df.single_id.tolist(), \n",
    "        persist_directory=CHROMA_DB_PERSIST_PATH.as_posix(),\n",
    "    )\n"
   ],
   "id": "7dc1ed2f4249ffc9",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:43.641518Z",
     "start_time": "2024-05-23T20:05:43.545960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "db_check = Chroma(\n",
    "    persist_directory=CHROMA_DB_PERSIST_PATH.as_posix(),\n",
    "    embedding_function=embeddings_llm,\n",
    ")\n",
    "db_check.get()"
   ],
   "id": "f475746c4170928",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T14:37:03.119010Z",
     "start_time": "2024-05-22T14:37:03.115110Z"
    }
   },
   "cell_type": "code",
   "source": "# db_check.get(include=['embeddings'])",
   "id": "5d2d60cf0ec55c70",
   "execution_count": 42,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-22T15:08:07.564700Z",
     "start_time": "2024-05-22T15:08:07.519977Z"
    }
   },
   "cell_type": "code",
   "source": "# db_check.delete_collection()",
   "id": "232d0e1ee52fb5ff",
   "execution_count": 62,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:21:05.502834Z",
     "start_time": "2024-05-21T09:52:55.322263Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# In memory vector store test!\n",
    "\n",
    "# Took more than 36min for 46 documents only; wow, I interrupted with the keyboard!\n",
    "# For model name as occiglot or mistral or sfr-embedding first on retrieval\n",
    "# db = DocArrayInMemorySearch.from_documents(documents, embedding=embeddings_llm)"
   ],
   "id": "bd7d4249e102ea32",
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for snowflake\n",
    "# db2 = DocArrayInMemorySearch.from_documents(documents, embedding=embeddings_llm) "
   ],
   "id": "9d2975291432835c",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:43.676683Z",
     "start_time": "2024-05-23T20:05:43.649407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for openai\n",
    "# db4 = DocArrayInMemorySearch.from_documents(documents, embedding=embeddings_llm)"
   ],
   "id": "4275c9eae893b756",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:43.680902Z",
     "start_time": "2024-05-23T20:05:43.678388Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load db from disk\n",
    "# db3 = Chroma(persist_directory=CHROMA_DB_PERSIST_PATH.as_posix(), embedding_function=embeddings_llm)\n",
    "# db3"
   ],
   "id": "e23dca038e93e09a",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Retriever for RAG",
   "id": "59cd98ac136a801a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:43.686297Z",
     "start_time": "2024-05-23T20:05:43.682012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 10}) # Occiglot or sfr-embed\n",
    "# retriever = db2.as_retriever(search_kwargs={\"k\": 10}) # snowflake\n",
    "# retriever = db4.as_retriever(search_kwargs={\"k\": 10}) #openAI\n",
    "# retriever = db3.as_retriever(search_kwargs={\"k\": 5})\n",
    "retriever"
   ],
   "id": "c580b555761db9fc",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:46.410087Z",
     "start_time": "2024-05-23T20:05:43.690017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test retriever\n",
    "query = \"AES\" \n",
    "retriever.invoke(query), len(retriever.invoke(query))"
   ],
   "id": "edc395197ac7abaa",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:46.416855Z",
     "start_time": "2024-05-23T20:05:46.412198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prompt template\n",
    "template = \"\"\"\n",
    "Réponds à la question uniquement grâce au contexte suivant et uniquement en langue française.\n",
    "Si tu n'as pas de réponse explicite dans le contexte, réponds \"Je n'ai pas assez d'informations pour répondre correctement\".\n",
    "\n",
    "Contexte : {context}\n",
    "\n",
    "Question : {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ],
   "id": "e04b7feeb5790a7b",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:46.425627Z",
     "start_time": "2024-05-23T20:05:46.417985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_docs(docs):\n",
    "    print([d.page_content for d in docs])\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ],
   "id": "b6beb2a70ad859d3",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:05:46.432663Z",
     "start_time": "2024-05-23T20:05:46.427520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "questions = [\n",
    "    # \"Qui est Oumar Diarra ?\",\n",
    "    # \"Quels sont les actions de l'EUTM ?\",\n",
    "    # \"Cite-moi les recommandations retenues lors du dialogue inter malien\",\n",
    "    # \"Quand finit la mission de l'union européenne ?\",\n",
    "    # \"Actualités sur la DIRPA\",\n",
    "    # \"Parle-moi de l'agriculture au Mali\",\n",
    "    # \"Que font les FAMA actuellement ?\"\n",
    "    \n",
    "    \"Parle moi du nouveau vérificateur général\",\n",
    "    \"Résume moi en quelques points les dernières actualités maintenant\",\n",
    "    \"Où en est la relation Mali et Russie ?\",\n",
    "    \"Qui est Bassaro Haïdara ?\",\n",
    "    \"Qu'est ce que Assimi a fait récemment ?\",\n",
    "    \"Le dialogue inter malien est il terminé ?\",\n",
    "    \"Qui sont les membres de l'AES ?\",\n",
    "    \"Comment a été la journée du 1er Mai au Mali ?\",\n",
    "    \"Donne moi la date la plus récente des informations dont tu disposes\",\n",
    "    \"Qu'en est il de la crise sécuritaire au Mali ?\",\n",
    "    \"La Belgique a t elle récemment collaborée avec le Mali ?\" # question bonus (must return I dont know)\n",
    "]\n",
    "len(questions)"
   ],
   "id": "e2c25a9197388c95",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-23T20:41:24.097870Z",
     "start_time": "2024-05-23T20:05:46.434204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for open source models\n",
    "for q in questions:\n",
    "    print(q)\n",
    "    print(chain.invoke(q))\n",
    "    print('-'*50, \"\\n\")"
   ],
   "id": "89bb453fad174648",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Récapitulatif",
   "id": "75dc12a11b946a69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- 8 bons retrieval sur 11 questions [V, V, V, X, V, V, X, V, X, V, V] : V → True response and X → Wrong response\n",
    "- 4 bonnes réponses sur 11 questions [X, V, V, X, V, X, X, X, X, X, V] :  V → True response and X → Wrong response\n",
    "- Bonne réponse à la question Bonus !\n",
    "- Questions potentielles à rajouter :\n",
    "    - Quand est ce que Abdoulaye Diop rencontrera ses homologues ?\n",
    "    -  Quoi de prévu le 28 juin à Bamako ?\n",
    "    - Quelle célébrité le président a rencontré ?\n",
    "    - À quand la transition civile au Mali ?"
   ],
   "id": "b4fdfa56c58bde45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Some results from OpenAIEmbeddings, far better result",
   "id": "ddd5fd27633320b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T15:48:44.407782Z",
     "start_time": "2024-05-21T15:17:35.183244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Result from OpenAI Embeddings\n",
    "for q in questions:\n",
    "    print(q)\n",
    "    print(chain.invoke(q))\n",
    "    print('-'*50, \"\\n\")"
   ],
   "id": "7b0a8ea0e30d79e7",
   "execution_count": 40,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
